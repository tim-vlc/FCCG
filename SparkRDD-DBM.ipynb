{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ad4f525-6d4b-4397-b1fb-80ff04a685de",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d732bfd-ef6b-45f5-b11e-3a842217b481",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def load_table_rdd(path):\n",
    "    \"\"\"\n",
    "    Load data from a CSV file into an RDD.\n",
    "    Assumes the CSV has a header which we skip.\n",
    "    \"\"\"\n",
    "    rdd = sc.textFile(path)\n",
    "    header = rdd.first() # extract header\n",
    "    rdd = rdd.filter(lambda row: row != header) # filter out header\n",
    "    return rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1540e03f-b84d-4acf-9f7c-3659a54ecb9c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "conf = SparkConf().setAppName(\"FCCG RDD Implementation\")\n",
    "sc = SparkContext.getOrCreate(conf=conf)\n",
    "\n",
    "# Load data into an RDD\n",
    "rdd = load_table_rdd('/FileStore/tables/web_Stanford.txt')\n",
    "#rdd = load_table_rdd('/FileStore/tables/web_NotreDame.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a208762-6d01-4711-bd41-2ace3e7f378c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def clean_table_rdd(rdd):\n",
    "    \"\"\"\n",
    "    Clean the RDD by splitting each line and converting to integer keys and values.\n",
    "    \"\"\"\n",
    "    return rdd.map(lambda line: line.split('\\t')) \\\n",
    "              .map(lambda kv: (int(kv[0]), int(kv[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb15f39a-2388-4afa-838b-26cf9f7e8ddb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "rdd = clean_table_rdd(rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "36eaf18d-e282-4df8-8bbf-521dd53fa27f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def fccg_iterate(rdd):\n",
    "    # MAP\n",
    "    rdd_mapped = rdd.union(rdd.map(lambda kv: (kv[1], kv[0])))\n",
    "    \n",
    "    # REDUCE\n",
    "    # Create adjacency list and find minimum value in each list\n",
    "    rdd_reduced = rdd_mapped.groupByKey().mapValues(lambda values: (list(set(values)), min(values)))\n",
    "    \n",
    "    # Filter the rows that have min_value lower than key\n",
    "    rdd_filtered = rdd_reduced.filter(lambda kv: kv[0] > kv[1][1])\n",
    "    \n",
    "    # Calculate the new pairs created\n",
    "    new_count = rdd_filtered.map(lambda kv: len(kv[1][0]) - 1).sum() # - rdd_filtered.count()\n",
    "    \n",
    "    # Prepare for next iteration\n",
    "    rdd_final = rdd_filtered.flatMap(lambda kv: [(k, kv[1][1]) for k in kv[1][0] + [kv[0]] ]).distinct()\n",
    "    \n",
    "    return rdd_final, new_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bbe7f4ff-81ac-4324-8433-cb754a70031e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def compute_fccg(rdd):\n",
    "    \"\"\"Main computation loop to find connected components.\"\"\"\n",
    "    nb_iteration = 0\n",
    "    \n",
    "    while True:\n",
    "        nb_iteration += 1\n",
    "        \n",
    "        rdd, count = fccg_iterate(rdd)\n",
    "\n",
    "        print(f\"Number of new pairs for iteration #{nb_iteration}:\\t{count}\")\n",
    "        if count == 0:\n",
    "            print(\"\\nNo new pair, end of computation\")\n",
    "            break\n",
    "            \n",
    "    return rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e459738c-22a1-4fb3-8ba9-390b5ae3cb31",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of new pairs for iteration #1:\t3525475\nNumber of new pairs for iteration #2:\t1635518\nNumber of new pairs for iteration #3:\t625639\nNumber of new pairs for iteration #4:\t643507\nNumber of new pairs for iteration #5:\t684584\nNumber of new pairs for iteration #6:\t347208\nNumber of new pairs for iteration #7:\t40104\nNumber of new pairs for iteration #8:\t14550\nNumber of new pairs for iteration #9:\t12241\nNumber of new pairs for iteration #10:\t9791\nNumber of new pairs for iteration #11:\t5558\nNumber of new pairs for iteration #12:\t1497\nNumber of new pairs for iteration #13:\t740\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Cancelled",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "final_rdd = compute_fccg(rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eaf3e65f-7949-415e-8cad-afce4d9b292b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[67]: 1"
     ]
    }
   ],
   "source": [
    "# Number of connected components in the graph\n",
    "final_rdd.map(lambda x: x[1]).distinct().count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "697d2b93-ff78-4e4a-9d8a-cc38a0cb4342",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "SparkRDD-DBM",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
